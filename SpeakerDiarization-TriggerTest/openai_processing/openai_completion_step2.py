import re
import logging
import json
from .openai_completion_core import client, log_token_usage, _parse_gpt_response
import os
from pathlib import Path

logger = logging.getLogger(__name__)

def extract_offset_from_line(line: str) -> tuple[str, str]:
    """è¡Œã‹ã‚‰æœ¬æ–‡ã¨offsetã‚’åˆ†é›¢ã™ã‚‹

    Args:
        line (str): å…¥åŠ›è¡Œï¼ˆä¾‹ï¼š'Speaker1: ã“ã‚“ã«ã¡ã¯ã€‚(12.5)'ï¼‰

    Returns:
        tuple[str, str]: (æœ¬æ–‡, offset) ã¾ãŸã¯ (å…ƒã®è¡Œ, '') ã®ã‚¿ãƒ—ãƒ«
    """
    match = re.match(r"(Speaker\d+: .*?)\s*\((\d+(\.\d+)?)\)$", line)
    if match:
        body = match.group(1).rstrip()    # ex. 'Speaker1: ã“ã‚“ã«ã¡ã¯ã€‚'
        offset = f"({match.group(2)})"    # ex. '(12.5)'
        return body, offset
    else:
        return line, ""  # offsetãªã—è¡Œ

def extract_last_sentence(text: str) -> str:
    """
    ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æœ€å¾Œã®æ–‡ï¼ˆå¥ç‚¹ã§çµ‚ã‚ã‚‹éƒ¨åˆ†ï¼‰ã‚’æŠ½å‡ºã™ã‚‹
    
    Args:
        text (str): å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
        
    Returns:
        str: æœ€å¾Œã®æ–‡ï¼ˆå¥ç‚¹ã§çµ‚ã‚ã‚‹éƒ¨åˆ†ï¼‰
    """
    if not text:
        return ""
    
    # Speakeréƒ¨åˆ†ã‚’é™¤å»
    if ":" in text:
        text = text.split(":", 1)[-1].strip()
    
    # å¥ç‚¹ã§åˆ†å‰²ã—ã¦æœ€å¾Œã®æ–‡ã‚’å–å¾—
    sentences = text.split("ã€‚")
    if len(sentences) > 1:
        # æœ€å¾Œã®æ–‡ï¼ˆå¥ç‚¹ã‚’å«ã‚€ï¼‰
        last_sentence = sentences[-2] + "ã€‚" if sentences[-2] else ""
        return last_sentence
    else:
        # å¥ç‚¹ãŒãªã„å ´åˆã¯å…¨ä½“ã‚’è¿”ã™
        return text

def extract_first_sentence(text: str) -> str:
    """
    ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æœ€åˆã®æ–‡ï¼ˆæœ€åˆã®å¥ç‚¹ã¾ã§ï¼‰ã‚’æŠ½å‡ºã™ã‚‹
    
    Args:
        text (str): å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
        
    Returns:
        str: æœ€åˆã®æ–‡ï¼ˆå¥ç‚¹ã§çµ‚ã‚ã‚‹éƒ¨åˆ†ï¼‰
    """
    if not text:
        return ""
    
    # Speakeréƒ¨åˆ†ã‚’é™¤å»
    if ":" in text:
        text = text.split(":", 1)[-1].strip()
    
    # æœ€åˆã®å¥ç‚¹ã¾ã§ã‚’å–å¾—
    if "ã€‚" in text:
        first_sentence = text.split("ã€‚")[0] + "ã€‚"
        return first_sentence
    else:
        # å¥ç‚¹ãŒãªã„å ´åˆã¯å…¨ä½“ã‚’è¿”ã™
        return text

def extract_last_complete_sentence(text: str) -> str:
    """
    æ–‡æœ«ã®å¥ç‚¹ã€Œã€‚ã€ã¾ã§å«ã‚€æœ€å¾Œã®æ–‡ã‚’æŠ½å‡º
    
    Args:
        text (str): å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
        
    Returns:
        str: æœ€å¾Œã®å®Œå…¨ãªæ–‡ï¼ˆå¥ç‚¹ã‚’å«ã‚€ï¼‰
    """
    if not text:
        return ""
    
    # Speakeréƒ¨åˆ†ã‚’é™¤å»
    if ":" in text:
        text = text.split(":", 1)[-1].strip()
    
    # å¥ç‚¹ã§çµ‚ã‚ã‚‹æ–‡ã‚’æ­£è¦è¡¨ç¾ã§æŠ½å‡º
    sentences = re.findall(r"[^ã€‚]*?ã€‚", text)
    return sentences[-1].strip() if sentences else text.strip()

def extract_last_sentence_no_period(text: str) -> str:
    """
    ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æœ€å¾Œã®æ–‡ã‚’æŠ½å‡ºã—ã€å¥ç‚¹ã‚’å‰Šé™¤ã™ã‚‹
    
    Args:
        text (str): å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
        
    Returns:
        str: æœ€å¾Œã®æ–‡ï¼ˆå¥ç‚¹ãªã—ï¼‰
    """
    if not text:
        return ""

    if ":" in text:
        text = text.split(":", 1)[-1].strip()

    sentences = text.split("ã€‚")
    if len(sentences) > 1:
        # æœ€å¾Œã®æ–‡ï¼ˆå¥ç‚¹ã‚’å‰Šé™¤ï¼‰
        last_sentence = sentences[-2] if sentences[-2] else ""
        return last_sentence
    else:
        # å¥ç‚¹ãŒãªã„å ´åˆã¯å…¨ä½“ã‚’è¿”ã™ï¼ˆå¥ç‚¹ãŒã‚ã‚Œã°å‰Šé™¤ï¼‰
        return text.strip("ã€‚")

def extract_first_sentence_no_period(text: str) -> str:
    """
    ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æœ€åˆã®æ–‡ã‚’æŠ½å‡ºã—ã€å¥ç‚¹ã‚’å‰Šé™¤ã™ã‚‹
    
    Args:
        text (str): å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
        
    Returns:
        str: æœ€åˆã®æ–‡ï¼ˆå¥ç‚¹ãªã—ï¼‰
    """
    if not text:
        return ""
    
    # Speakeréƒ¨åˆ†ã‚’é™¤å»
    if ":" in text:
        text = text.split(":", 1)[-1].strip()
    
    # æœ€åˆã®å¥ç‚¹ã¾ã§ã‚’å–å¾—ï¼ˆå¥ç‚¹ã‚’å‰Šé™¤ï¼‰
    if "ã€‚" in text:
        first_sentence = text.split("ã€‚")[0]
        return first_sentence
    else:
        # å¥ç‚¹ãŒãªã„å ´åˆã¯å…¨ä½“ã‚’è¿”ã™
        return text

def step2_complete_incomplete_sentences(segments: list) -> list:
    """
    ã‚¹ãƒ†ãƒƒãƒ—2: æ‹¬å¼§å†…ç™ºè©±ã®å‰å¾Œæ¥ç¶šè‡ªç„¶ã•ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°è©•ä¾¡ï¼ˆå¥ç‚¹å‰Šé™¤ãƒ»è‡ªç„¶æ¥ç¶šåˆ¤å®šï¼‰
    
    Args:
        segments (list): æ–‡å­—åˆ—ãƒªã‚¹ãƒˆï¼ˆå„è¡ŒãŒ "SpeakerX: æœ¬æ–‡(offset)" å½¢å¼ï¼‰
        
    Returns:
        list: å‡¦ç†æ¸ˆã¿ã®æ–‡å­—åˆ—ãƒªã‚¹ãƒˆï¼ˆã‚¹ã‚³ã‚¢ä»˜ãï¼‰
    """
    logger.info("ã‚¹ãƒ†ãƒƒãƒ—2: æ‹¬å¼§å†…ç™ºè©±ã®å‰å¾Œæ¥ç¶šè‡ªç„¶ã•ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°è©•ä¾¡ï¼ˆå¥ç‚¹å‰Šé™¤ãƒ»è‡ªç„¶æ¥ç¶šåˆ¤å®šï¼‰ã‚’é–‹å§‹")
    logger.info(f"å…¥åŠ›ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°: {len(segments)}")
    
    if not segments:
        return segments
    
    result_segments = []
    processed_count = 0
    bracket_count = 0
    
    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®æº–å‚™
    output_path = Path("outputs/completion_result_step2.txt")
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    for i, segment in enumerate(segments):
        if not isinstance(segment, str) or not segment.strip():
            result_segments.append(segment)
            continue
        
        segment = segment.strip()
        logger.debug(f"å‡¦ç†ä¸­: {i+1}/{len(segments)} - {segment}")
        
        # æ‹¬å¼§å†…ç™ºè©±ã‹ã©ã†ã‹ã‚’æœ€åˆã«ãƒã‚§ãƒƒã‚¯
        if segment.startswith("Speaker") and "ï¼ˆ" in segment and "ï¼‰" in segment:
            bracket_count += 1
            logger.info(f"æ‹¬å¼§å†…ç™ºè©±ã‚’ç™ºè¦‹: {segment}")
            
            body, offset = extract_offset_from_line(segment)
            
            # æ‹¬å¼§å†…ã ã‘ã®ç™ºè©±ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
            body_without_speaker = body.split(":", 1)[-1].strip()
            if body_without_speaker.startswith("ï¼ˆ") and body_without_speaker.endswith("ï¼‰"):
                logger.info(f"æ‹¬å¼§å†…ã ã‘ã®ç™ºè©±ã‚’ç¢ºèª: {body_without_speaker}")
                
                # å‰å¾Œã®è¡Œã‚’å–å¾—
                prev_segment = segments[i - 1] if i > 0 else ""
                next_segment = segments[i + 1] if i < len(segments) - 1 else ""
                
                # å‰å¾Œã®è¡Œã‹ã‚‰æœ¬æ–‡ã‚’æŠ½å‡º
                prev_body, _ = extract_offset_from_line(prev_segment)
                next_body, _ = extract_offset_from_line(next_segment)
                
                # æ‹¬å¼§ã®å†…å®¹ã‚’æŠ½å‡º
                bracket_content = body_without_speaker[1:-1]  # ï¼ˆï¼‰ã‚’é™¤å»
                
                # å‰ã®ç™ºè©±ã®æœ€å¾Œã®å®Œå…¨ãªæ–‡ã‚’æŠ½å‡º
                front_complete_sentence = extract_last_complete_sentence(prev_body)
                # å¥ç‚¹ã‚’å‰Šé™¤ã—ãŸå‰æ–‡ã‚’å–å¾—
                front_sentence = extract_last_sentence_no_period(prev_body)
                # å¥ç‚¹ã‚’å‰Šé™¤ã—ãŸå¾Œæ–‡ã‚’å–å¾—
                back_sentence = extract_first_sentence_no_period(next_body)
                bracket_no_period = bracket_content.strip("ã€‚")
                
                logger.info(f"å‰ã®å®Œå…¨æ–‡: {front_complete_sentence}")
                logger.info(f"å‰ã®æ–‡ï¼ˆå¥ç‚¹ãªã—ï¼‰: {front_sentence}")
                logger.info(f"æ‹¬å¼§å†…ï¼ˆå¥ç‚¹ãªã—ï¼‰: {bracket_no_period}")
                logger.info(f"å¾Œã®æ–‡ï¼ˆå¥ç‚¹ãªã—ï¼‰: {back_sentence}")
                
                # ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°è©•ä¾¡ã‚’å®Ÿè¡Œ
                score_result = evaluate_connection_naturalness_no_period(front_sentence, bracket_no_period, back_sentence)
                
                # çµæœã‚’é©ç”¨
                front_score = score_result.get("front_score", 0.0)
                back_score = score_result.get("back_score", 0.0)
                
                logger.info(f"å‰æ¥ç¶šã‚¹ã‚³ã‚¢: {front_score}, å¾Œæ¥ç¶šã‚¹ã‚³ã‚¢: {back_score}")
                
                # ã‚¹ã‚³ã‚¢ä»˜ãã®çµæœè¡Œã‚’ä½œæˆ
                speaker_prefix = body.split(':', 1)[0]
                scored_segment = f"{speaker_prefix}: ï¼ˆ{bracket_content}ï¼‰{offset} [å‰:{front_score:.1f} å¾Œ:{back_score:.1f}]"
                
                # çµæœã‚’è¿½åŠ 
                result_segments.append(scored_segment)
                processed_count += 1
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½è¨˜å‡ºåŠ›
                with open(output_path, "a", encoding="utf-8") as f:
                    f.write(scored_segment + "\n")
                
                logger.info(f"ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°å®Œäº†: {segment} â†’ {scored_segment}")
                
            else:
                # æ‹¬å¼§å†…ã ã‘ã®ç™ºè©±ã§ãªã„å ´åˆã¯ãã®ã¾ã¾
                logger.debug(f"æ‹¬å¼§å†…ã ã‘ã®ç™ºè©±ã§ã¯ãªã„ãŸã‚ã‚¹ã‚­ãƒƒãƒ—: {body_without_speaker}")
                result_segments.append(segment)
        else:
            # æ‹¬å¼§ä»˜ãã§ãªã„å ´åˆã¯ãã®ã¾ã¾
            result_segments.append(segment)
    
    logger.info(f"æ‹¬å¼§ã‚’å«ã‚€ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°: {bracket_count}")
    logger.info(f"ã‚¹ãƒ†ãƒƒãƒ—2å®Œäº†: {processed_count}ä»¶ã®æ‹¬å¼§å†…ç™ºè©±ã‚’ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°è©•ä¾¡")
    
    # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã®ã‚µãƒãƒªãƒ¼ã‚’å‡ºåŠ›
    from .openai_completion_core import total_tokens_used
    logger.info(f"ğŸ§¾ Step2 Total Token Usage: {total_tokens_used}")
    
    return result_segments

def complete_utterance_with_openai(text: str) -> str:
    """
    OpenAIã‚’ä½¿ç”¨ã—ã¦ä¸å®Œå…¨ãªç™ºè©±ã‚’è£œå®Œã™ã‚‹
    """
    if not text.strip():
        return text
    
    prompt = f"""
ä»¥ä¸‹ã®ä¸å®Œå…¨ãªç™ºè©±ã‚’è‡ªç„¶ã«è£œå®Œã—ã¦ãã ã•ã„ã€‚è£œå®Œã™ã‚‹éš›ã¯ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦ãã ã•ã„ï¼š

1. å…ƒã®æ–‡ã®æ„å‘³ã‚’å¤‰ãˆãªã„
2. è‡ªç„¶ãªæ—¥æœ¬èªã«ãªã‚‹ã‚ˆã†ã«è£œå®Œ
3. è£œå®Œéƒ¨åˆ†ã¯ã€ã€‘ã§å›²ã‚€
4. å…ƒã®æ–‡ãŒæ—¢ã«å®Œå…¨ãªå ´åˆã¯è£œå®Œã—ãªã„

ä¸å®Œå…¨ãªç™ºè©±: {text}

è£œå®Œçµæœ:"""

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯æ—¥æœ¬èªã®ä¼šè©±ã‚’è‡ªç„¶ã«è£œå®Œã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=200
        )
        
        result = response.choices[0].message.content.strip()
        log_token_usage(response.usage, "step2_complete")
        
        # è£œå®Œçµæœã‚’è§£æ
        parsed_result = _parse_gpt_response(result)
        if parsed_result and "completed_text" in parsed_result:
            return parsed_result["completed_text"]
        else:
            return text
        
    except Exception as e:
        logger.error(f"OpenAIè£œå®Œã‚¨ãƒ©ãƒ¼: {e}")
        return text

def complete_utterance_with_openai_text(text: str) -> str:
    """ã‚¹ãƒ†ãƒƒãƒ—2-â‘ ï¼šæ‹¬å¼§ä»˜ãã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®è£œå®Œå‡¦ç†ï¼ˆæ–‡å­—åˆ—ãƒ™ãƒ¼ã‚¹ï¼‰

    Args:
        text (str): å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆï¼ˆæ”¹è¡ŒåŒºåˆ‡ã‚Šã®è¡Œï¼‰

    Returns:
        str: è£œå®Œå¾Œã®ãƒ†ã‚­ã‚¹ãƒˆ
    """
    if not text or not text.strip():
        return text
    
    lines = text.strip().split('\n')
    result_lines = []
    completion_count = 0
    
    for i, line in enumerate(lines):
        line = line.strip()
        if not line:
            result_lines.append(line)
            continue
        
        # æœ¬æ–‡ã¨offsetã‚’åˆ†é›¢
        body, offset = extract_offset_from_line(line)
        
        # æ‹¬å¼§ä»˜ãã‚»ã‚°ãƒ¡ãƒ³ãƒˆï¼ˆç›¸æ§Œï¼‰ã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯
        if (body.startswith("ï¼ˆ") and body.endswith("ï¼‰")):
            
            # å‰å¾Œã®è¡Œã‚’å–å¾—
            prev_line = lines[i - 1] if i > 0 else ""
            next_line = lines[i + 1] if i < len(lines) - 1 else ""
            
            # å‰å¾Œã®è¡Œã‹ã‚‰æœ¬æ–‡ã‚’æŠ½å‡º
            prev_body, _ = extract_offset_from_line(prev_line)
            next_body, _ = extract_offset_from_line(next_line)
            
            # æ‹¬å¼§ã®å†…å®¹ã‚’æŠ½å‡º
            bracket_content = body[1:-1]  # ï¼ˆï¼‰ã‚’é™¤å»
            
            # GPT-4oã«è£œå®Œã‚’ä¾é ¼
            system_message = """ã‚ãªãŸã¯ä¼šè©±ã®æ–‡è„ˆã‚’ç†è§£ã—ã€æ‹¬å¼§ä»˜ãã®æ–­ç‰‡çš„ãªç™ºè©±ã‚’è‡ªç„¶ã«è£œå®Œã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚

ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦ã€å‰å¾Œã®æ–‡è„ˆã‚’è€ƒæ…®ã—ãªãŒã‚‰æ‹¬å¼§å†…ã®å†…å®¹ã‚’è£œå®Œã—ã¦ãã ã•ã„ï¼š

1. æ‹¬å¼§å†…ã®æ–­ç‰‡çš„ãªèªå¥ï¼ˆä¾‹ï¼šã€Œå¤«ã§ã™ã€‚ã€ï¼‰ã‚’æ–‡è„ˆä¸Šæœ€ã‚‚è‡ªç„¶ãªå½¢ã«è£œå®Œã™ã‚‹
2. å‰å¾Œã®ç™ºè©±å†…å®¹ã‚’å‚ç…§ã—ã¦ã€æœ€ã‚‚é©åˆ‡ãªè£œå®Œèªã‚’æ¨å®šã™ã‚‹
3. ä¾‹ï¼šã€Œå¤§ä¸ˆã€‚ã€ã€Œå¤«ã§ã™ã€‚ã€â†’ã€Œå¤§ä¸ˆå¤«ã§ã™ã€‚ã€
4. è£œå®ŒãŒä¸ç¢ºå®Ÿãªå ´åˆã¯å…ƒã®å†…å®¹ã‚’ãã®ã¾ã¾ä¿æŒã™ã‚‹
5. ä¼šè©±ã®è‡ªç„¶ãªæµã‚Œã‚’ç¶­æŒã™ã‚‹

å‡ºåŠ›å½¢å¼ï¼š
{
    "completed_text": "è£œå®Œå¾Œã®æ‹¬å¼§å†…ãƒ†ã‚­ã‚¹ãƒˆ",
    "completion_confidence": 0.0-1.0  // è£œå®Œã®ç¢ºä¿¡åº¦ï¼ˆ0.8ä»¥ä¸Šã§è£œå®Œå®Ÿè¡Œï¼‰
}"""

            user_message = f"""å‰ã®æ–‡: {prev_body}
æ‹¬å¼§å†…: {bracket_content}
æ¬¡ã®æ–‡: {next_body}

ä¸Šè¨˜ã®ä¼šè©±ã«å¯¾ã—ã¦ã€æ‹¬å¼§å†…ã®å†…å®¹ã‚’è£œå®Œã—ã¦ãã ã•ã„ã€‚"""

            try:
                response = client.chat.completions.create(
                    model=os.environ.get("OPENAI_MODEL", "gpt-4o"),
                    messages=[
                        {"role": "system", "content": system_message},
                        {"role": "user", "content": user_message}
                    ],
                    temperature=0.1
                )

                # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’è¨˜éŒ²
                tokens = response.usage.total_tokens
                log_token_usage(tokens, "ã‚¹ãƒ†ãƒƒãƒ—2-â‘ è£œå®Œ")

                result_text = response.choices[0].message.content.strip()
                
                # JSONãƒ‘ãƒ¼ã‚¹ã®è©¦è¡Œ
                parsed_result = _parse_gpt_response(result_text)
                
                if parsed_result:
                    completed_text = parsed_result.get("completed_text", bracket_content)
                    confidence = parsed_result.get("completion_confidence", 0.0)
                    
                    # ç¢ºä¿¡åº¦ãŒ0.8ä»¥ä¸Šã®å ´åˆã®ã¿è£œå®Œã‚’å®Ÿè¡Œ
                    if confidence >= 0.8:
                        completed_body = f"ï¼ˆ{completed_text}ï¼‰"
                        completion_count += 1
                    else:
                        completed_body = body
                else:
                    completed_body = body
                    
            except Exception as e:
                # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯å…ƒã®å†…å®¹ã‚’ä¿æŒ
                completed_body = body
        
        else:
            # æ‹¬å¼§ä»˜ãã§ãªã„å ´åˆã¯ãã®ã¾ã¾
            completed_body = body
        
        # offsetã‚’ä»˜ã‘ã¦çµæœè¡Œã‚’ä½œæˆ
        result_line = f"{completed_body}{offset}"
        result_lines.append(result_line)
    
    logger.info(f"ã‚¹ãƒ†ãƒƒãƒ—2-â‘ å®Œäº†: {completion_count}ä»¶ã®æ‹¬å¼§ä»˜ãã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’è£œå®Œ")
    return "\n".join(result_lines)

def complete_utterance_with_openai(segments: list) -> list:
    """
    ã‚¹ãƒ†ãƒƒãƒ—2-â‘¡ï¼šä¸å®Œå…¨ãªç™ºè©±ã®è£œå®Œå‡¦ç†ï¼ˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ™ãƒ¼ã‚¹ï¼‰
    """
    logger.info("ã‚¹ãƒ†ãƒƒãƒ—2-â‘¡: ä¸å®Œå…¨ãªç™ºè©±ã®è£œå®Œã‚’é–‹å§‹")
    
    result_segments = []
    completion_count = 0
    
    for segment in segments:
        if not isinstance(segment, dict):
            result_segments.append(segment)
            continue
        
        text = segment.get("text", "")
        if not text:
            result_segments.append(segment)
            continue
        
        # ä¸å®Œå…¨ãªç™ºè©±ã®è£œå®Œ
        completed_text = complete_utterance_with_openai(text)
        
        if completed_text != text:
            segment["text"] = completed_text
            completion_count += 1
        
        result_segments.append(segment)
    
    logger.info(f"ã‚¹ãƒ†ãƒƒãƒ—2-â‘¡å®Œäº†: {completion_count}ä»¶ã®ç™ºè©±ã‚’è£œå®Œ")
    return result_segments

def evaluate_connection_naturalness(prev_text: str, bracket_text: str, next_text: str) -> dict:
    """
    æ‹¬å¼§å†…ç™ºè©±ã®å‰å¾Œæ¥ç¶šã®è‡ªç„¶ã•ã‚’ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°è©•ä¾¡ã™ã‚‹
    
    Args:
        prev_text (str): å‰ã®ç™ºè©±
        bracket_text (str): æ‹¬å¼§å†…ã®ç™ºè©±
        next_text (str): æ¬¡ã®ç™ºè©±
        
    Returns:
        dict: å‰æ¥ç¶šã‚¹ã‚³ã‚¢ã¨å¾Œæ¥ç¶šã‚¹ã‚³ã‚¢ã‚’å«ã‚€è¾æ›¸
    """
    system_message = """
ã‚ãªãŸã¯ä¼šè©±ã®è‡ªç„¶ã•ã‚’è©•ä¾¡ã™ã‚‹è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚
ä¸ãˆã‚‰ã‚ŒãŸ2ã¤ã®æ–‡ã‚’æ¯”è¼ƒã—ã€ã©ã¡ã‚‰ãŒæ—¥æœ¬èªã®ä¼šè©±ã¨ã—ã¦ã‚ˆã‚Šè‡ªç„¶ã‹ã‚’åˆ¤æ–­ã—ã€ãã‚Œãã‚Œã« 0.0ã€œ1.0 ã®ã‚¹ã‚³ã‚¢ã‚’ä¸ãˆã¦ãã ã•ã„ã€‚

è©•ä¾¡åŸºæº–ï¼š
- 1.0: éå¸¸ã«è‡ªç„¶ã§è‡ªç„¶ãªä¼šè©±
- 0.8-0.9: è‡ªç„¶ã§ç†è§£ã—ã‚„ã™ã„
- 0.6-0.7: ã‚„ã‚„ä¸è‡ªç„¶ã ãŒç†è§£å¯èƒ½
- 0.4-0.5: ä¸è‡ªç„¶ã§ç†è§£ã—ã«ãã„
- 0.2-0.3: éå¸¸ã«ä¸è‡ªç„¶
- 0.0-0.1: æ–‡æ³•çš„ã«ç ´ç¶»ã—ã¦ã„ã‚‹

å‡ºåŠ›å½¢å¼ï¼š
{
  "front_score": 0.0-1.0,
  "back_score": 0.0-1.0
}"""

    user_message = f"""æ¬¡ã®2ã¤ã®æ–‡ã‚’æ¯”è¼ƒã—ã¦ãã ã•ã„ï¼š

1. å‰æ–‡æ¥ç¶š: {prev_text}{bracket_text}
2. å¾Œæ–‡æ¥ç¶š: {bracket_text}{next_text}

å„æ–‡ã«ã¤ã„ã¦è‡ªç„¶ã•ã‚’è©•ä¾¡ã—ã€ä»¥ä¸‹ã®å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š
{{
  "front_score": 0.0-1.0,
  "back_score": 0.0-1.0
}}"""

    try:
        response = client.chat.completions.create(
            model=os.environ.get("OPENAI_MODEL", "gpt-3.5-turbo"),
            messages=[
                {"role": "system", "content": system_message},
                {"role": "user", "content": user_message}
            ],
            temperature=0.1,
            max_tokens=200
        )
        
        # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã®ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›
        total_tokens = response.usage.total_tokens
        prompt_tokens = response.usage.prompt_tokens
        completion_tokens = response.usage.completion_tokens
        
        logger.debug(f"ğŸ§¾ Step2 Scoring Token Usage - Prompt: {prompt_tokens}, Completion: {completion_tokens}, Total: {total_tokens}")
        
        result = response.choices[0].message.content.strip()
        log_token_usage(response.usage.total_tokens, "step2_scoring_evaluation")
        
        # JSONãƒ‘ãƒ¼ã‚¹
        parsed_result = _parse_gpt_response(result)
        if parsed_result:
            return {
                "front_score": float(parsed_result.get("front_score", 0.0)),
                "back_score": float(parsed_result.get("back_score", 0.0))
            }
        else:
            # ãƒ‘ãƒ¼ã‚¹å¤±æ•—æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¹ã‚³ã‚¢
            return {
                "front_score": 0.5,
                "back_score": 0.5
            }
            
    except Exception as e:
        logger.error(f"ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
        return {
            "front_score": 0.5,
            "back_score": 0.5
        }

def evaluate_connection_naturalness_sentence(front_sentence: str, bracket_text: str, back_sentence: str) -> dict:
    """
    æ‹¬å¼§å†…ç™ºè©±ã®å‰å¾Œæ¥ç¶šã®è‡ªç„¶ã•ã‚’ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°è©•ä¾¡ã™ã‚‹ï¼ˆæ–‡å˜ä½å¯¾å¿œï¼‰
    
    Args:
        front_sentence (str): å‰ã®æ–‡ï¼ˆå¥ç‚¹ã§çµ‚ã‚ã‚‹ï¼‰
        bracket_text (str): æ‹¬å¼§å†…ã®ç™ºè©±
        back_sentence (str): å¾Œã®æ–‡ï¼ˆå¥ç‚¹ã§çµ‚ã‚ã‚‹ï¼‰
        
    Returns:
        dict: å‰æ¥ç¶šã‚¹ã‚³ã‚¢ã¨å¾Œæ¥ç¶šã‚¹ã‚³ã‚¢ã‚’å«ã‚€è¾æ›¸
    """
    system_message = """
ã‚ãªãŸã¯ä¼šè©±ã®è‡ªç„¶ã•ã‚’è©•ä¾¡ã™ã‚‹æ—¥æœ¬èªå°‚é–€ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚
ä¸ãˆã‚‰ã‚ŒãŸ2ã¤ã®æ–‡ã«ã¤ã„ã¦ã€ãã‚Œãã‚Œã®è‡ªç„¶ã•ã‚’0.0ã€œ1.0ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

è©•ä¾¡åŸºæº–ï¼š
- 1.0: éå¸¸ã«è‡ªç„¶ã§è‡ªç„¶ãªä¼šè©±
- 0.8-0.9: è‡ªç„¶ã§ç†è§£ã—ã‚„ã™ã„
- 0.6-0.7: ã‚„ã‚„ä¸è‡ªç„¶ã ãŒç†è§£å¯èƒ½
- 0.4-0.5: ä¸è‡ªç„¶ã§ç†è§£ã—ã«ãã„
- 0.2-0.3: éå¸¸ã«ä¸è‡ªç„¶
- 0.0-0.1: æ–‡æ³•çš„ã«ç ´ç¶»ã—ã¦ã„ã‚‹

å‡ºåŠ›å½¢å¼ï¼š
{
  "front_score": 0.0-1.0,
  "back_score": 0.0-1.0
}"""

    user_message = f"""æ¬¡ã®2ã¤ã®æ–‡ã‚’æ¯”è¼ƒã—ã¦ãã ã•ã„ï¼š

1. å‰æ–‡æ¥ç¶š: {front_sentence}{bracket_text}
2. å¾Œæ–‡æ¥ç¶š: {bracket_text}{back_sentence}

å„æ–‡ã«ã¤ã„ã¦è‡ªç„¶ã•ã‚’è©•ä¾¡ã—ã€ä»¥ä¸‹ã®å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š
{{
  "front_score": 0.0-1.0,
  "back_score": 0.0-1.0
}}"""

    try:
        response = client.chat.completions.create(
            model=os.environ.get("OPENAI_MODEL", "gpt-3.5-turbo"),
            messages=[
                {"role": "system", "content": system_message},
                {"role": "user", "content": user_message}
            ],
            temperature=0.1,
            max_tokens=200
        )
        
        # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã®ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›
        total_tokens = response.usage.total_tokens
        prompt_tokens = response.usage.prompt_tokens
        completion_tokens = response.usage.completion_tokens
        
        logger.debug(f"ğŸ§¾ Step2 Sentence Scoring Token Usage - Prompt: {prompt_tokens}, Completion: {completion_tokens}, Total: {total_tokens}")
        
        result = response.choices[0].message.content.strip()
        log_token_usage(response.usage.total_tokens, "step2_sentence_scoring_evaluation")
        
        # JSONãƒ‘ãƒ¼ã‚¹
        parsed_result = _parse_gpt_response(result)
        if parsed_result:
            return {
                "front_score": float(parsed_result.get("front_score", 0.0)),
                "back_score": float(parsed_result.get("back_score", 0.0))
            }
        else:
            # ãƒ‘ãƒ¼ã‚¹å¤±æ•—æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¹ã‚³ã‚¢
            return {
                "front_score": 0.5,
                "back_score": 0.5
            }
            
    except Exception as e:
        logger.error(f"æ–‡å˜ä½ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
        return {
            "front_score": 0.5,
            "back_score": 0.5
        }

def evaluate_connection_naturalness_no_period(front_sentence: str, bracket_text: str, back_sentence: str) -> dict:
    """
    æ‹¬å¼§å†…ç™ºè©±ã®å‰å¾Œæ¥ç¶šã®è‡ªç„¶ã•ã‚’ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°è©•ä¾¡ã™ã‚‹ï¼ˆå¥ç‚¹å‰Šé™¤ãƒ»è‡ªç„¶æ¥ç¶šåˆ¤å®šï¼‰
    
    Args:
        front_sentence (str): å‰ã®æ–‡ï¼ˆå¥ç‚¹ãªã—ï¼‰
        bracket_text (str): æ‹¬å¼§å†…ã®ç™ºè©±ï¼ˆå¥ç‚¹ãªã—ï¼‰
        back_sentence (str): å¾Œã®æ–‡ï¼ˆå¥ç‚¹ãªã—ï¼‰
        
    Returns:
        dict: å‰æ¥ç¶šã‚¹ã‚³ã‚¢ã¨å¾Œæ¥ç¶šã‚¹ã‚³ã‚¢ã‚’å«ã‚€è¾æ›¸
    """
    system_message = """
ã‚ãªãŸã¯ä¼šè©±ã®è‡ªç„¶ã•ã‚’åˆ¤å®šã™ã‚‹æ—¥æœ¬èªç‰¹åŒ–ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚
2ã¤ã®æ–‡ã®è‡ªç„¶ã•ã‚’æ¯”è¼ƒã—ã€ãã‚Œãã‚Œã‚¹ã‚³ã‚¢ï¼ˆ0.0ã€œ1.0ï¼‰ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

è©•ä¾¡åŸºæº–ï¼š
- 1.0: æ–‡æ³•çš„ã«æ­£ã—ãã€æ„å‘³ãŒé€šã˜ã‚‹è‡ªç„¶ãªä¼šè©±
- 0.8-0.9: ã»ã¼è‡ªç„¶ã§ç†è§£ã—ã‚„ã™ã„
- 0.6-0.7: ã‚„ã‚„ä¸è‡ªç„¶ã ãŒç†è§£å¯èƒ½
- 0.4-0.5: ä¸è‡ªç„¶ã§ç†è§£ã—ã«ãã„
- 0.2-0.3: éå¸¸ã«ä¸è‡ªç„¶
- 0.0-0.1: æ–‡æ³•çš„ã«ç ´ç¶»ã—ã¦ã„ã‚‹ã€æ„å‘³ä¸æ˜

ç‰¹ã«ä»¥ä¸‹ã®ç‚¹ã‚’é‡è¦–ã—ã¦ãã ã•ã„ï¼š
- æ–‡æ³•çš„ãªæ­£ã—ã•
- æ„å‘³ã®é€šã˜ã‚„ã™ã•
- æ—¥æœ¬èªã¨ã—ã¦è‡ªç„¶ãªèªé †
- æ•¬èªã‚„ä¸å¯§èªã®é©åˆ‡ãªä½¿ç”¨

å‡ºåŠ›å½¢å¼ï¼š
{
  "front_score": 0.0-1.0,
  "back_score": 0.0-1.0
}"""

    user_message = f"""æ¬¡ã®2ã¤ã®æ–‡ã‚’æ¯”è¼ƒã—ã¦ãã ã•ã„ï¼š

1. å‰æ–‡æ¥ç¶š: {front_sentence}{bracket_text}
2. å¾Œæ–‡æ¥ç¶š: {bracket_text}{back_sentence}

å„æ–‡ã«ã¤ã„ã¦è‡ªç„¶ã•ã‚’è©•ä¾¡ã—ã€ä»¥ä¸‹ã®å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š
{{
  "front_score": 0.0-1.0,
  "back_score": 0.0-1.0
}}"""

    try:
        response = client.chat.completions.create(
            model=os.environ.get("OPENAI_MODEL", "gpt-3.5-turbo"),
            messages=[
                {"role": "system", "content": system_message},
                {"role": "user", "content": user_message}
            ],
            temperature=0.1,
            max_tokens=200
        )
        
        # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã®ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›
        total_tokens = response.usage.total_tokens
        prompt_tokens = response.usage.prompt_tokens
        completion_tokens = response.usage.completion_tokens
        
        logger.debug(f"ğŸ§¾ Step2 No Period Scoring Token Usage - Prompt: {prompt_tokens}, Completion: {completion_tokens}, Total: {total_tokens}")
        
        result = response.choices[0].message.content.strip()
        log_token_usage(response.usage.total_tokens, "step2_no_period_scoring_evaluation")
        
        # JSONãƒ‘ãƒ¼ã‚¹
        parsed_result = _parse_gpt_response(result)
        if parsed_result:
            return {
                "front_score": float(parsed_result.get("front_score", 0.0)),
                "back_score": float(parsed_result.get("back_score", 0.0))
            }
        else:
            # ãƒ‘ãƒ¼ã‚¹å¤±æ•—æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¹ã‚³ã‚¢
            return {
                "front_score": 0.5,
                "back_score": 0.5
            }
            
    except Exception as e:
        logger.error(f"å¥ç‚¹å‰Šé™¤ç‰ˆã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
        return {
            "front_score": 0.5,
            "back_score": 0.5
        } 