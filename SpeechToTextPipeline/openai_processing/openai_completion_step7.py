import re
import time
import traceback
from typing import List, Dict, Any, Tuple
import os
import logging
import openai

logger = logging.getLogger(__name__)

# OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
client = openai.OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

def log_token_usage(tokens: int, operation: str):
    """ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’è¨˜éŒ²ã™ã‚‹"""
    try:
        logging.info(f"ğŸ”¢ ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡: {tokens} ({operation})")
    except Exception as e:
        logging.warning(f"ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡è¨˜éŒ²ã‚¨ãƒ©ãƒ¼: {e}")

def extract_offset_from_line(line: str) -> tuple[str, float]:
    """è¡Œã‹ã‚‰æœ¬æ–‡ã¨offsetã‚’åˆ†é›¢ã™ã‚‹

    Args:
        line (str): å…¥åŠ›è¡Œï¼ˆä¾‹ï¼š'Speaker1: ã“ã‚“ã«ã¡ã¯ã€‚(12.5)'ï¼‰

    Returns:
        tuple[str, float]: (æœ¬æ–‡, offset) ã¾ãŸã¯ (å…ƒã®è¡Œ, None) ã®ã‚¿ãƒ—ãƒ«
    """
    match = re.match(r"(Speaker\d+: .+?)\(([\d.]+)\)$", line)
    if match:
        body = match.group(1).rstrip()    # ex. 'Speaker1: ã“ã‚“ã«ã¡ã¯ã€‚'
        offset = float(match.group(2))    # ex. 12.5
        return body, offset
    else:
        return line, None  # offsetãªã—è¡Œ

def generate_summary_title(conversation_text: str, block_index: int, total_blocks: int) -> str:
    """OpenAI APIã‚’ä½¿ç”¨ã—ã¦ä¼šè©±ãƒ–ãƒ­ãƒƒã‚¯ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆã™ã‚‹

    Args:
        conversation_text (str): ä¼šè©±ãƒ†ã‚­ã‚¹ãƒˆ
        block_index (int): ãƒ–ãƒ­ãƒƒã‚¯ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        total_blocks (int): ç·ãƒ–ãƒ­ãƒƒã‚¯æ•°

    Returns:
        str: ç”Ÿæˆã•ã‚ŒãŸã‚¿ã‚¤ãƒˆãƒ«
    """
    try:
        # æœ€åˆã¨æœ€å¾Œã®ãƒ–ãƒ­ãƒƒã‚¯ã®æ¨å¥¨ã‚¿ã‚¤ãƒˆãƒ«
        if block_index == 0:
            suggested_title = "ã‚¢ã‚¤ã‚¹ãƒ–ãƒ¬ã‚¤ã‚¯"
        elif block_index == total_blocks - 1:
            suggested_title = "ã‚¢ãƒå–ã‚Š"
        else:
            suggested_title = ""

        system_message = """ä»¥ä¸‹ã®ä¼šè©±ãƒ–ãƒ­ãƒƒã‚¯ã®å†…å®¹ã‚’åˆ†æã—ã€20æ–‡å­—ä»¥å†…ã®é©åˆ‡ãªã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆã®ãƒ«ãƒ¼ãƒ«ï¼š
- 20æ–‡å­—ä»¥å†…ã§ç°¡æ½”ã«
- ä¼šè©±ã®ä¸»è¦ãªãƒ†ãƒ¼ãƒã‚„ç›®çš„ã‚’è¡¨ç¾
- æœ€åˆã®ãƒ–ãƒ­ãƒƒã‚¯ã¯ã€Œã‚¢ã‚¤ã‚¹ãƒ–ãƒ¬ã‚¤ã‚¯ã€ã€æœ€å¾Œã®ãƒ–ãƒ­ãƒƒã‚¯ã¯ã€Œã‚¢ãƒå–ã‚Šã€ã‚’æ¨å¥¨
- ãŸã ã—ã€å†…å®¹ã«åˆã‚ãªã„å ´åˆã¯åˆ¥ã®é©åˆ‡ãªã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆ
- å‡ºåŠ›ã¯ã‚¿ã‚¤ãƒˆãƒ«ã®ã¿ï¼ˆèª¬æ˜ä¸è¦ï¼‰

å‡ºåŠ›ä¾‹ï¼š
ã‚¢ã‚¤ã‚¹ãƒ–ãƒ¬ã‚¤ã‚¯
æ¥­ç•Œç´¹ä»‹
å•†å“èª¬æ˜
ã‚¢ãƒå–ã‚Š"""

        user_message = f"""ä¼šè©±ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆ{block_index + 1}/{total_blocks}ï¼‰ï¼š
{conversation_text}

æ¨å¥¨ã‚¿ã‚¤ãƒˆãƒ«ï¼š{suggested_title}

ã‚¿ã‚¤ãƒˆãƒ«ï¼š"""

        response = client.chat.completions.create(
            model=os.environ.get("OPENAI_MODEL", "gpt-3.5-turbo"),
            messages=[
                {"role": "system", "content": system_message},
                {"role": "user", "content": user_message}
            ],
            temperature=0.3,
            max_tokens=50
        )

        # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’è¨˜éŒ²
        try:
            tokens_used = response.usage.total_tokens
            log_token_usage(tokens_used, "ä¼šè©±è¦ç´„ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ")
        except (AttributeError, KeyError):
            pass

        title = response.choices[0].message.content.strip()
        
        # æ¨å¥¨ã‚¿ã‚¤ãƒˆãƒ«ãŒé©åˆ‡ãªå ´åˆã¯ä½¿ç”¨
        if block_index == 0 and "ã‚¢ã‚¤ã‚¹ãƒ–ãƒ¬ã‚¤ã‚¯" in title:
            return "ã‚¢ã‚¤ã‚¹ãƒ–ãƒ¬ã‚¤ã‚¯"
        elif block_index == total_blocks - 1 and "ã‚¢ãƒå–ã‚Š" in title:
            return "ã‚¢ãƒå–ã‚Š"
        else:
            return title[:20]  # 20æ–‡å­—ä»¥å†…ã«åˆ¶é™
            
    except Exception as e:
        logger.error(f"ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¿ã‚¤ãƒˆãƒ«ã‚’è¿”ã™
        if block_index == 0:
            return "ã‚¢ã‚¤ã‚¹ãƒ–ãƒ¬ã‚¤ã‚¯"
        elif block_index == total_blocks - 1:
            return "ã‚¢ãƒå–ã‚Š"
        else:
            return f"ä¼šè©±ãƒ–ãƒ­ãƒƒã‚¯{block_index + 1}" 