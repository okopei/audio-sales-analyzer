import re
import logging
import json
import os
import openai

logger = logging.getLogger(__name__)

# OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
client = openai.OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

def log_token_usage(tokens: int, operation: str):
    """ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’è¨˜éŒ²ã™ã‚‹"""
    try:
        logging.info(f"ğŸ”¢ ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡: {tokens} ({operation})")
    except Exception as e:
        logging.warning(f"ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡è¨˜éŒ²ã‚¨ãƒ©ãƒ¼: {e}")

def _parse_gpt_response(response_text: str) -> dict:
    """GPTãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’JSONã¨ã—ã¦è§£æã™ã‚‹"""
    try:
        # JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡º
        json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
        if json_match:
            json_str = json_match.group(0)
            return json.loads(json_str)
        else:
            # JSONãƒ–ãƒ­ãƒƒã‚¯ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€æ•°å€¤ã‚’æŠ½å‡º
            numbers = re.findall(r'\d+\.?\d*', response_text)
            if len(numbers) >= 2:
                return {
                    "front_score": float(numbers[0]),
                    "back_score": float(numbers[1])
                }
        return None
    except Exception as e:
        logger.error(f"GPTãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æã‚¨ãƒ©ãƒ¼: {e}")
        return None

def evaluate_connection_naturalness_no_period(front_text: str, bracket_text: str, back_text: str) -> dict:
    """
    æ‹¬å¼§å†…ç™ºè©±ã®å‰å¾Œæ¥ç¶šã®è‡ªç„¶ã•ã‚’ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°è©•ä¾¡ã™ã‚‹ï¼ˆå¥ç‚¹å‰Šé™¤ãƒ»è‡ªç„¶æ¥ç¶šåˆ¤å®šï¼‰

    Args:
        front_text (str): å‰ã®æ–‡ï¼ˆå¥ç‚¹ãªã—ï¼‰
        bracket_text (str): æ‹¬å¼§å†…ã®ç™ºè©±ï¼ˆå¥ç‚¹ãªã—ï¼‰
        back_text (str): å¾Œã®æ–‡ï¼ˆå¥ç‚¹ãªã—ï¼‰

    Returns:
        dict: å‰æ¥ç¶šã‚¹ã‚³ã‚¢ã¨å¾Œæ¥ç¶šã‚¹ã‚³ã‚¢ã‚’å«ã‚€è¾æ›¸
    """
    system_message = """
ã‚ãªãŸã¯ä¼šè©±ã®è‡ªç„¶ã•ã‚’åˆ¤å®šã™ã‚‹æ—¥æœ¬èªç‰¹åŒ–ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚
2ã¤ã®æ–‡ã®è‡ªç„¶ã•ã‚’æ¯”è¼ƒã—ã€ãã‚Œãã‚Œã‚¹ã‚³ã‚¢ï¼ˆ0.0ã€œ1.0ï¼‰ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

è©•ä¾¡åŸºæº–ï¼š
- 1.0: æ–‡æ³•çš„ã«æ­£ã—ãã€æ„å‘³ãŒé€šã˜ã‚‹è‡ªç„¶ãªä¼šè©±
- 0.8-0.9: ã»ã¼è‡ªç„¶ã§ç†è§£ã—ã‚„ã™ã„
- 0.6-0.7: ã‚„ã‚„ä¸è‡ªç„¶ã ãŒç†è§£å¯èƒ½
- 0.4-0.5: ä¸è‡ªç„¶ã§ç†è§£ã—ã«ãã„
- 0.2-0.3: éå¸¸ã«ä¸è‡ªç„¶
- 0.0-0.1: æ–‡æ³•çš„ã«ç ´ç¶»ã—ã¦ã„ã‚‹ã€æ„å‘³ä¸æ˜

ç‰¹ã«ä»¥ä¸‹ã®ç‚¹ã‚’é‡è¦–ã—ã¦ãã ã•ã„ï¼š
- æ–‡æ³•çš„ãªæ­£ã—ã•
- æ„å‘³ã®é€šã˜ã‚„ã™ã•
- æ—¥æœ¬èªã¨ã—ã¦è‡ªç„¶ãªèªé †
- æ•¬èªã‚„ä¸å¯§èªã®é©åˆ‡ãªä½¿ç”¨

å‡ºåŠ›å½¢å¼ï¼š
{
  "front_score": 0.0-1.0,
  "back_score": 0.0-1.0
}
"""

    user_message = f"""æ¬¡ã®2ã¤ã®æ–‡ã‚’æ¯”è¼ƒã—ã¦ãã ã•ã„ï¼š

1. å‰æ–‡æ¥ç¶š: {front_text}{bracket_text}
2. å¾Œæ–‡æ¥ç¶š: {bracket_text}{back_text}

å„æ–‡ã«ã¤ã„ã¦è‡ªç„¶ã•ã‚’è©•ä¾¡ã—ã€ä»¥ä¸‹ã®å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š
{{
  "front_score": 0.0-1.0,
  "back_score": 0.0-1.0
}}"""

    try:
        response = client.chat.completions.create(
            model=os.environ.get("OPENAI_MODEL", "gpt-3.5-turbo"),
            messages=[
                {"role": "system", "content": system_message},
                {"role": "user", "content": user_message}
            ],
            temperature=0.1,
            max_tokens=200
        )

        result = response.choices[0].message.content.strip()
        log_token_usage(response.usage.total_tokens, "step2_no_period_scoring_evaluation")

        parsed_result = _parse_gpt_response(result)
        if parsed_result:
            return {
                "front_score": float(parsed_result.get("front_score", 0.0)),
                "back_score": float(parsed_result.get("back_score", 0.0))
            }
        else:
            return {"front_score": 0.5, "back_score": 0.5}

    except Exception as e:
        logger.error(f"å¥ç‚¹å‰Šé™¤ç‰ˆã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
        return {"front_score": 0.5, "back_score": 0.5}
