'use client'

import { useState, useRef, useEffect } from 'react'
import { BlockBlobClient } from '@azure/storage-blob'
import { useRouter } from 'next/navigation'

interface TranscriptionResponse {
  status: string
  original_text?: string
  error?: string
  steps?: {
    file_received: boolean
    speech_recognition_completed: boolean
  }
}

interface UploadResponse {
  success: boolean
  url?: string
  error?: string
}

export const useRecording = () => {
  const router = useRouter()
  const [isRecording, setIsRecording] = useState(false)
  const [transcription, setTranscription] = useState<TranscriptionResponse | null>(null)
  const [processingStatus, setProcessingStatus] = useState('')
  const [uploadStatus, setUploadStatus] = useState<UploadResponse | null>(null)
  const [isUploading, setIsUploading] = useState(false)
  const [hasUploaded, setHasUploaded] = useState(false) // ä¸€åº¦ã ã‘ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãŸã‚ã®ãƒ•ãƒ©ã‚°
  const [hasNavigated, setHasNavigated] = useState(false) // ä¸€åº¦ã ã‘é·ç§»ã™ã‚‹ãŸã‚ã®ãƒ•ãƒ©ã‚°
  const mediaRecorderRef = useRef<MediaRecorder | null>(null)
  const chunksRef = useRef<Blob[]>([])
  const [isPaused, setIsPaused] = useState(false)
  const [recordingTime, setRecordingTime] = useState(0)
  const timerRef = useRef<ReturnType<typeof setInterval> | null>(null)
  const [recordingBlob, setRecordingBlob] = useState<Blob | null>(null)
  const recordingBlobRef = useRef<Blob | null>(null) // ç›´æ¥å‚ç…§ã™ã‚‹ãŸã‚ã®Ref
  // éŸ³å£°ãƒ¬ãƒ™ãƒ«æ¤œå‡ºç”¨ã®çŠ¶æ…‹ã¨å‚ç…§
  const [audioLevel, setAudioLevel] = useState<number[]>(Array(50).fill(0))
  const audioContextRef = useRef<AudioContext | null>(null)
  const analyserRef = useRef<AnalyserNode | null>(null)
  const audioDataRef = useRef<Uint8Array | null>(null)
  const animationFrameRef = useRef<number | null>(null)
  const mediaStreamRef = useRef<MediaStream | null>(null)

  const formatTime = (seconds: number) => {
    const hours = Math.floor(seconds / 3600)
    const minutes = Math.floor((seconds % 3600) / 60)
    const secs = seconds % 60
    return `${hours.toString().padStart(2, '0')}:${minutes.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`
  }

  const startTimer = () => {
    if (timerRef.current) {
      clearInterval(timerRef.current)
    }
    timerRef.current = setInterval(() => {
      setRecordingTime(prev => prev + 1)
    }, 1000)
  }

  // éŸ³å£°ãƒ¬ãƒ™ãƒ«ã‚’æ›´æ–°ã™ã‚‹é–¢æ•°
  const updateAudioLevel = () => {
    if (!analyserRef.current || !audioDataRef.current) return
    
    analyserRef.current.getByteFrequencyData(audioDataRef.current)
    
    // éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å¹³å‡ãƒ¬ãƒ™ãƒ«ã‚’è¨ˆç®—
    const average = audioDataRef.current.reduce((sum, value) => sum + value, 0) / audioDataRef.current.length
    
    // æ–°ã—ã„é…åˆ—ã‚’ä½œæˆï¼ˆå¤ã„å€¤ã‚’ã‚·ãƒ•ãƒˆã—ã¦æ–°ã—ã„å€¤ã‚’è¿½åŠ ï¼‰
    setAudioLevel(prev => {
      const newLevels = [...prev.slice(1), Math.min(100, average)]
      return newLevels
    })
    
    // ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç¶™ç¶š
    animationFrameRef.current = requestAnimationFrame(updateAudioLevel)
  }

  // ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ã‚¢ãƒ³ãƒã‚¦ãƒ³ãƒˆæ™‚ã«ãƒªã‚½ãƒ¼ã‚¹ã‚’è§£æ”¾
  useEffect(() => {
    return () => {
      if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
        audioContextRef.current.close()
      }
      
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current)
      }
      
      if (mediaStreamRef.current) {
        mediaStreamRef.current.getTracks().forEach(track => track.stop())
      }
    }
  }, [])

  // Blobä¿å­˜ç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
  const saveRecordingBlob = (blob: Blob) => {
    console.log(`saveRecordingBlob: ä¿å­˜ã™ã‚‹Blob - ã‚µã‚¤ã‚º=${blob.size}, type=${blob.type}`);
    
    // ä¸¡æ–¹ã«ä¿å­˜ã—ã¦ç¢ºå®Ÿã«ã‚­ãƒ£ãƒ—ãƒãƒ£ã™ã‚‹
    setRecordingBlob(blob);
    recordingBlobRef.current = blob;
  };

  const startRecording = async () => {
    try {
      // ãƒªã‚»ãƒƒãƒˆ
      setRecordingBlob(null);
      recordingBlobRef.current = null;
      chunksRef.current = [];
      setHasUploaded(false); // ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
      setHasNavigated(false); // é·ç§»ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
      
      console.log("éŒ²éŸ³ã‚’é–‹å§‹ã—ã¾ã™: åˆæœŸåŒ–å®Œäº†");
      
      // ã™ã§ã«ä½¿ç”¨ä¸­ã®ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¹ãƒˆãƒªãƒ¼ãƒ ãŒã‚ã‚Œã°åœæ­¢
      if (mediaStreamRef.current) {
        mediaStreamRef.current.getTracks().forEach(track => track.stop())
      }
      
      // AudioContextãŒæ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆã¯é–‰ã˜ã‚‹
      if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
        audioContextRef.current.close()
      }
      
      // æ–°ã—ã„ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å–å¾—
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: { 
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        } 
      })
      
      mediaStreamRef.current = stream
      
      // AudioContextã¨AnalyserNodeã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
      audioContextRef.current = new (window.AudioContext || (window as any).webkitAudioContext)()
      analyserRef.current = audioContextRef.current.createAnalyser()
      analyserRef.current.fftSize = 256
      
      const source = audioContextRef.current.createMediaStreamSource(stream)
      source.connect(analyserRef.current)
      
      // FFTãƒ‡ãƒ¼ã‚¿é…åˆ—ã‚’ä½œæˆ
      const bufferLength = analyserRef.current.frequencyBinCount
      audioDataRef.current = new Uint8Array(bufferLength)
      
      // éŸ³å£°ãƒ¬ãƒ™ãƒ«ç›£è¦–ã‚’é–‹å§‹
      animationFrameRef.current = requestAnimationFrame(updateAudioLevel)
      
      // MediaRecorderã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³
      const options: MediaRecorderOptions = {
        audioBitsPerSecond: 128000, // éŸ³è³ªã‚’æŒ‡å®šï¼ˆ128kbpsï¼‰
        mimeType: 'audio/webm'
      }
      
      // ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ¬ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’åˆæœŸåŒ–
      console.log("MediaRecorderã‚’åˆæœŸåŒ–ã—ã¾ã™:", options);
      const mediaRecorder = new MediaRecorder(stream, options);
      
      mediaRecorderRef.current = mediaRecorder
      
      // ãƒ‡ãƒ¼ã‚¿ãƒãƒ£ãƒ³ã‚¯è¿½åŠ ãƒ­ã‚°ç”¨ã®ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
      let chunkCounter = 0
      
      mediaRecorder.ondataavailable = (e) => {
        console.log(`ãƒ‡ãƒ¼ã‚¿åˆ©ç”¨å¯èƒ½ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿ: ã‚µã‚¤ã‚º=${e.data.size}, type=${e.data.type}`);
        if (e.data.size > 0) {
          // 10ãƒãƒ£ãƒ³ã‚¯ã”ã¨ã«1å›ã ã‘ãƒ­ã‚°ã‚’å‡ºåŠ›
          chunkCounter++
          if (chunkCounter % 5 === 0 || chunkCounter === 1) {
            console.log(`éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿è¿½åŠ : ${chunkCounter}å€‹ç›®, ${e.data.size} bytes, type: ${e.data.type}`)
          }
          chunksRef.current.push(e.data)
          
          // å¿…è¦ã«å¿œã˜ã¦é€”ä¸­çµŒéã®Blobã‚’ä½œæˆï¼ˆé•·æ™‚é–“éŒ²éŸ³æ™‚ã®ä¿é™ºï¼‰
          if (chunkCounter % 10 === 0) {
            try {
              // å®Ÿéš›ã®MIMEã‚¿ã‚¤ãƒ—ã‚’å–å¾—
              const mimeType = mediaRecorder.mimeType || 'audio/webm';
              const tempBlob = new Blob(chunksRef.current, { type: mimeType });
              console.log(`é€”ä¸­çµŒéã®Blobç”Ÿæˆ: ${tempBlob.size} bytes, type: ${mimeType}`);
              // çŠ¶æ…‹ã¯æ›´æ–°ã›ãšã€å‚ç…§ã®ã¿ä¿æŒ
              recordingBlobRef.current = tempBlob;
            } catch (error) {
              console.error("é€”ä¸­çµŒéã®Blobç”Ÿæˆã‚¨ãƒ©ãƒ¼:", error);
            }
          }
        }
      }

      mediaRecorder.onstop = () => {
        console.log("MediaRecorder.onstopã‚¤ãƒ™ãƒ³ãƒˆãŒç™ºç”Ÿã—ã¾ã—ãŸ");
        // éŒ²éŸ³åœæ­¢æ™‚ã«éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’Blobã¨ã—ã¦ä¿å­˜
        if (chunksRef.current.length > 0) {
          console.log(`éŒ²éŸ³åœæ­¢: ${chunksRef.current.length}å€‹ã®ãƒ‡ãƒ¼ã‚¿ãƒãƒ£ãƒ³ã‚¯`)
          const totalSize = chunksRef.current.reduce((acc, chunk) => acc + chunk.size, 0)
          console.log(`éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿åˆè¨ˆã‚µã‚¤ã‚º: ${totalSize} bytes`)
          
          try {
            const mimeType = mediaRecorder.mimeType || 'audio/webm';
            console.log(`Blobç”Ÿæˆé–‹å§‹: mimeType=${mimeType}, ãƒãƒ£ãƒ³ã‚¯æ•°=${chunksRef.current.length}`);
            
            // ãƒãƒ£ãƒ³ã‚¯ã®è©³ç´°ã‚’ãƒ­ã‚°å‡ºåŠ›
            chunksRef.current.slice(0, 3).forEach((chunk, i) => {
              console.log(`ãƒãƒ£ãƒ³ã‚¯${i}: ã‚µã‚¤ã‚º=${chunk.size}, type=${chunk.type}`);
            });
            
            const blob = new Blob(chunksRef.current, { type: mimeType });
            console.log(`Blobç”Ÿæˆå®Œäº†: ${blob.size} bytes, type: ${blob.type}`);
            
            // ä¸¡æ–¹ã«ä¿å­˜
            saveRecordingBlob(blob);
          } catch (error) {
            console.error("Blobç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:", error);
          }
        } else {
          console.warn('éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“')
        }
        
        // éŸ³å£°ãƒ¬ãƒ™ãƒ«ç›£è¦–ã‚’åœæ­¢
        if (animationFrameRef.current) {
          cancelAnimationFrame(animationFrameRef.current)
          animationFrameRef.current = null
        }
      }

      // ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
      mediaRecorder.onerror = (event) => {
        console.error("MediaRecorderã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:", event);
      };

      startTimer()
      // ã‚ˆã‚Šå°ã•ãªã‚¿ã‚¤ãƒ ã‚¹ãƒ©ã‚¤ã‚¹ã«è¨­å®šã—ã¦é »ç¹ã«ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
      mediaRecorder.start(500)
      console.log("éŒ²éŸ³ã‚’é–‹å§‹ã—ã¾ã—ãŸ");
      setIsRecording(true)
    } catch (error) {
      console.error('éŒ²éŸ³é–‹å§‹ã‚¨ãƒ©ãƒ¼:', error)
    }
  }

  const stopRecording = () => {
    if (mediaRecorderRef.current) {
      console.log("éŒ²éŸ³ã‚’åœæ­¢ã—ã¾ã™");
      
      // è¿½åŠ ï¼šã‚‚ã—æ—¢ã«éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã¯ä¿æŒã™ã‚‹
      if (chunksRef.current.length > 0) {
        console.log("éŒ²éŸ³åœæ­¢ç›´å‰ã®ãƒ‡ãƒ¼ã‚¿ç¢ºèª:", { 
          chunksLength: chunksRef.current.length,
          totalSize: chunksRef.current.reduce((acc, chunk) => acc + chunk.size, 0)
        })
        
        try {
          // recordingBlobã‚’ã™ãã«ä½œæˆï¼ˆã‚¹ãƒ†ãƒ¼ãƒˆæ›´æ–°ã®å‰ã«ï¼‰
          const mimeType = mediaRecorderRef.current.mimeType || 'audio/webm';
          const blob = new Blob(chunksRef.current, { type: mimeType })
          console.log("stopRecordingå†…ã§Blobç”Ÿæˆ:", {
            size: blob.size,
            type: blob.type
          })
          
          // ä¸¡æ–¹ã«ä¿å­˜
          saveRecordingBlob(blob);
        } catch (error) {
          console.error("stopRecordingå†…ã®Blobç”Ÿæˆã‚¨ãƒ©ãƒ¼:", error);
        }
      } else {
        console.warn("éŒ²éŸ³åœæ­¢æ™‚ã«ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“");
      }
      
      // MediaRecorderã®åœæ­¢
      try {
        mediaRecorderRef.current.stop()
        console.log("MediaRecorder.stop()ãŒæ­£å¸¸ã«å‘¼ã³å‡ºã•ã‚Œã¾ã—ãŸ");
      } catch (error) {
        console.error("MediaRecorder.stop()ã‚¨ãƒ©ãƒ¼:", error);
      }
      
      // ã‚¿ã‚¤ãƒãƒ¼ã¨UIã®æ›´æ–°
      if (timerRef.current) {
        clearInterval(timerRef.current)
        timerRef.current = null
      }
      setIsRecording(false)
      setRecordingTime(0)
      
      // éŸ³å£°ãƒ¬ãƒ™ãƒ«ç›£è¦–ã‚’åœæ­¢
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current)
        animationFrameRef.current = null
      }
      
      // ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®ãƒˆãƒ©ãƒƒã‚¯ã‚’åœæ­¢
      if (mediaStreamRef.current) {
        mediaStreamRef.current.getTracks().forEach(track => track.stop())
      }
    }
  }

  const getRecordingBlob = (): Blob | null => {
    console.log("getRecordingBlobå‘¼ã³å‡ºã—:", {
      hasChunks: chunksRef.current.length > 0,
      hasRecordingBlob: !!recordingBlob,
      hasRecordingBlobRef: !!recordingBlobRef.current,
    });
    
    // å„ªå…ˆé †ä½: 1. refã®Blob, 2. stateã®Blob, 3. ãƒãƒ£ãƒ³ã‚¯ã‹ã‚‰æ–°è¦ä½œæˆ
    if (recordingBlobRef.current) {
      return recordingBlobRef.current;
    }
    
    if (recordingBlob) {
      return recordingBlob;
    }
    
    if (chunksRef.current.length > 0) {
      try {
        // å®Ÿéš›ã®MIMEã‚¿ã‚¤ãƒ—ã‚’å–å¾—
        const mimeType = mediaRecorderRef.current?.mimeType || 'audio/webm';
        const blob = new Blob(chunksRef.current, { type: mimeType });
        console.log(`ãƒãƒ£ãƒ³ã‚¯ã‹ã‚‰æ–°è¦Blobç”Ÿæˆ: ${blob.size} bytes, type: ${mimeType}`);
        // ä½œæˆã—ãŸBlobã‚’ä¿å­˜ã—ã¦ãŠã
        saveRecordingBlob(blob);
        return blob;
      } catch (error) {
        console.error("getRecordingBlobå†…ã®Blobç”Ÿæˆã‚¨ãƒ©ãƒ¼:", error);
      }
    }
    
    return null;
  }

  const getRecordingData = (): Blob | null => {
    // ã‚ˆã‚Šç¢ºå®Ÿã«éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹ãŸã‚ã«æ©Ÿèƒ½å¼·åŒ–
    return getRecordingBlob();
  }

  // è¿½åŠ : ç¾åœ¨ã®éŸ³å£°ãƒ¬ãƒ™ãƒ«ã‚’å–å¾—ã™ã‚‹ãƒ†ã‚¹ãƒˆé–¢æ•°
  const testMicrophone = async (): Promise<boolean> => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
      // ãƒ†ã‚¹ãƒˆæˆåŠŸå¾Œã«ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢
      stream.getTracks().forEach(track => track.stop())
      return true
    } catch (error) {
      console.error("ãƒã‚¤ã‚¯ã®ãƒ†ã‚¹ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ:", error)
      return false
    }
  }

  const sendAudioToServer = async (audioBlob: Blob, meetingId?: string, userId?: string): Promise<UploadResponse> => {
    try {
      console.log('ğŸ”µ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰é–‹å§‹:', {
        blobSize: audioBlob.size,
        blobType: audioBlob.type,
        timestamp: new Date().toISOString(),
        meetingId,
        userId,
        hasMeetingId: !!meetingId,
        hasUserId: !!userId
      })
      
      setIsUploading(true)
      setProcessingStatus(`éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­... (å½¢å¼: ${audioBlob.type}, ã‚µã‚¤ã‚º: ${(audioBlob.size / 1024 / 1024).toFixed(2)}MB)`)
      
      // ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆã®å…±é€šé–¢æ•°
      const formatTimestamp = (date: Date): string => {
        return date.toISOString().replace(/:/g, '-').replace(/\..+/, match =>
          `-${match.slice(1, -1)}`
        )
      }
      
      const generateFileName = (meetingId: string | undefined, userId: string | undefined, extension: string = '.webm'): string => {
        const timestamp = formatTimestamp(new Date())
        
        if (meetingId && userId) {
          return `meeting_${meetingId}_user_${userId}_${timestamp}${extension}`
        } else if (userId) {
          return `recording_user_${userId}_${timestamp}${extension}`
        } else {
          return `recording_${timestamp}${extension}`
        }
      }
      
      // ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æ±ºå®š
      const fileName = generateFileName(meetingId, userId, '.webm')
      console.log('ğŸ“ ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«å:', {
        fileName,
        meetingId,
        userId,
        timestamp: formatTimestamp(new Date())
      })
      const file = new File([audioBlob], fileName, { type: 'audio/webm' })
      
      console.log('ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ:', {
        fileName,
        fileSize: file.size,
        fileType: file.type
      })
      
      // SASãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
      console.log('ğŸ”‘ SASãƒˆãƒ¼ã‚¯ãƒ³å–å¾—é–‹å§‹')
      const sasResponse = await fetch(`/api/azure/get-sas-token?fileName=${encodeURIComponent(fileName)}`)
      
      if (!sasResponse.ok) {
        const errorText = await sasResponse.text()
        console.error('âŒ SASãƒˆãƒ¼ã‚¯ãƒ³å–å¾—ã‚¨ãƒ©ãƒ¼:', {
          status: sasResponse.status,
          errorText
        })
        throw new Error(`SASãƒˆãƒ¼ã‚¯ãƒ³ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: ${sasResponse.status} ${errorText}`)
      }
      
      const { sasUrl } = await sasResponse.json()
      console.log('âœ… SAS URLå–å¾—æˆåŠŸ:', sasUrl.split('?')[0]) // ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®ãŸã‚SASãƒˆãƒ¼ã‚¯ãƒ³éƒ¨åˆ†ã¯çœç•¥
      
      // BlockBlobClientã‚’ä½¿ç”¨ã—ã¦ç›´æ¥ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
      console.log('ğŸ“¤ Azure Storageç›´æ¥ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰é–‹å§‹')
      const blobClient = new BlockBlobClient(sasUrl)
      
      await blobClient.uploadData(file, {
        blobHTTPHeaders: {
          blobContentType: file.type
        }
      })
      
      console.log('âœ… ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æˆåŠŸ')
      
      setProcessingStatus('ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†')
      setUploadStatus({ success: true, url: sasUrl.split('?')[0] }) // SASãƒˆãƒ¼ã‚¯ãƒ³ãªã—ã®URLã‚’è¿”ã™
      
      // ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æˆåŠŸå¾Œã€2ç§’å¾Œã«ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã«è‡ªå‹•é·ç§»
      setTimeout(() => {
        if (!hasNavigated) {
          console.log('ğŸ”„ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã«è‡ªå‹•é·ç§»')
          setHasNavigated(true)
          router.push('/dashboard')
        }
      }, 2000)
      
      return { success: true, url: sasUrl.split('?')[0] }
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ'
      console.error('âŒ Error uploading audio:', error)
      setProcessingStatus('ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ')
      setUploadStatus({ success: false, error: errorMessage })
      
      return { success: false, error: errorMessage }
    } finally {
      setIsUploading(false)
    }
  }

  const pauseRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      try {
        mediaRecorderRef.current.pause()
        if (timerRef.current) {
          clearInterval(timerRef.current)
          timerRef.current = null
        }
        setIsPaused(true)
      } catch (error) {
        console.error('Pause error:', error)
      }
    }
  }

  const resumeRecording = () => {
    if (mediaRecorderRef.current && isPaused) {
      try {
        mediaRecorderRef.current.resume()
        startTimer()
        setIsPaused(false)
      } catch (error) {
        console.error('Resume error:', error)
      }
    }
  }

  const updateRecordingState = async (value: boolean) => {
    if (value && mediaRecorderRef.current) return
    if (!value && !mediaRecorderRef.current) return

    if (value && !mediaRecorderRef.current) {
      await startRecording()
    } else if (!value && mediaRecorderRef.current) {
      stopRecording()
    }
  }

  // éŒ²éŸ³åœæ­¢æ™‚ã®è‡ªå‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†
  useEffect(() => {
    if (!isRecording && recordingBlob && !isUploading && !hasUploaded) {
      console.log('ğŸ”„ éŒ²éŸ³åœæ­¢ã‚’æ¤œçŸ¥ã€è‡ªå‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚’é–‹å§‹')
      console.log('ğŸ“Š ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¡ä»¶ç¢ºèª:', {
        isRecording,
        hasRecordingBlob: !!recordingBlob,
        isUploading,
        hasUploaded
      })
      
      // URLãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰meetingIdã¨userIdã‚’å–å¾—
      const urlParams = new URLSearchParams(window.location.search)
      const meetingId = urlParams.get('meetingId')
      const userId = urlParams.get('userId')
      
      console.log('ğŸ” è‡ªå‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ™‚ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:', {
        meetingId,
        userId,
        hasMeetingId: !!meetingId,
        hasUserId: !!userId
      })
      
      // meetingIdã¨userIdã‚’æ¸¡ã—ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
      sendAudioToServer(recordingBlob, meetingId || undefined, userId || undefined)
      setHasUploaded(true) // ä¸€åº¦ã ã‘å®Ÿè¡Œã™ã‚‹ãŸã‚ã®ãƒ•ãƒ©ã‚°
    }
  }, [isRecording, recordingBlob, isUploading, hasUploaded])

  return {
    isRecording,
    transcription,
    processingStatus,
    uploadStatus,
    isUploading,
    hasUploaded,
    startRecording,
    stopRecording,
    isPaused,
    pauseRecording,
    resumeRecording,
    setIsRecording: updateRecordingState,
    recordingTime,
    formatTime,
    getRecordingBlob,
    getRecordingData,
    recordingBlob,
    audioLevel, // éŸ³å£°ãƒ¬ãƒ™ãƒ«ã®é…åˆ—ã‚’è¿”ã™
    testMicrophone, // ãƒã‚¤ã‚¯ãƒ†ã‚¹ãƒˆé–¢æ•°ã‚’è¿½åŠ 
    sendAudioToServer // æ‰‹å‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”¨
  }
} 